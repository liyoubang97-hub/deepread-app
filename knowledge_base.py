"""
DeepRead - çŸ¥è¯†åº“ç³»ç»Ÿ
ä½¿ç”¨ChromaDBå®ç°æœ¬åœ°å‘é‡å­˜å‚¨å’ŒçŸ¥è¯†å…³è”
"""

import os
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
import json
from pathlib import Path
from datetime import datetime

# å‘é‡æ•°æ®åº“
import chromadb
from chromadb.config import Settings

# æ–‡æœ¬åµŒå…¥ï¼ˆä½¿ç”¨Hugging Faceå…è´¹æ¨¡å‹ï¼‰
from sentence_transformers import SentenceTransformer


@dataclass
class KnowledgeCard:
    """çŸ¥è¯†å¡ç‰‡"""
    id: str
    book_title: str
    book_author: str
    content_type: str  # "insight", "quote", "concept", "example"
    content: str
    tags: List[str]
    created_at: str

    def to_dict(self):
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict):
        return cls(**data)


class PersonalKnowledgeBase:
    """ä¸ªäººçŸ¥è¯†åº“ - æœ¬åœ°å‘é‡å­˜å‚¨"""

    def __init__(self, persist_directory: str = "./knowledge_db"):
        """
        åˆå§‹åŒ–çŸ¥è¯†åº“
        persist_directory: æ•°æ®åº“å­˜å‚¨è·¯å¾„
        """
        self.persist_dir = Path(persist_directory)
        self.persist_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–ChromaDBï¼ˆæŒä¹…åŒ–åˆ°æœ¬åœ°ï¼‰
        self.chroma_client = chromadb.PersistentClient(
            path=str(self.persist_dir / "chroma")
        )

        # åˆ›å»ºæˆ–è·å–collection
        self.collection = self.chroma_client.get_or_create_collection(
            name="knowledge_cards",
            metadata={"hnsw:space": "cosine"}  # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        )

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡ä¸‹è½½åä¼šç¼“å­˜åˆ°æœ¬åœ°ï¼‰
        print("ğŸ“¦ åŠ è½½åµŒå…¥æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡ä¼šä¸‹è½½ï¼Œçº¦400MBï¼‰...")
        self.embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    def add_book_knowledge(
        self,
        book_title: str,
        book_author: str,
        analysis: Dict
    ) -> List[str]:
        """
        å°†ä¹¦ç±åˆ†æç»“æœæ·»åŠ åˆ°çŸ¥è¯†åº“
        è¿”å›ï¼šæ·»åŠ çš„å¡ç‰‡IDåˆ—è¡¨
        """
        card_ids = []
        timestamp = datetime.now().isoformat()

        # æ·»åŠ æ ¸å¿ƒè§‚ç‚¹
        for i, insight in enumerate(analysis.get("key_insights", [])):
            card = KnowledgeCard(
                id=f"{book_title}_insight_{i}_{timestamp}",
                book_title=book_title,
                book_author=book_author,
                content_type="insight",
                content=insight,
                tags=[book_title, "æ ¸å¿ƒè§‚ç‚¹", "æ·±åº¦æ€è€ƒ"],
                created_at=timestamp
            )
            self._add_card(card)
            card_ids.append(card.id)

        # æ·»åŠ é‡‘å¥
        for i, quote in enumerate(analysis.get("quotes", [])):
            card = KnowledgeCard(
                id=f"{book_title}_quote_{i}_{timestamp}",
                book_title=book_title,
                book_author=book_author,
                content_type="quote",
                content=quote,
                tags=[book_title, "é‡‘å¥", "å¯åˆ†äº«"],
                created_at=timestamp
            )
            self._add_card(card)
            card_ids.append(card.id)

        # æ·»åŠ æ¦‚å¿µï¼ˆä»æ€ç»´å¯¼å›¾æå–ï¼‰
        mind_map = analysis.get("mind_map", {})
        for branch in mind_map.get("ä¸»è¦åˆ†æ”¯", []):
            branch_name = branch.get("åˆ†æ”¯å", "")
            for concept in branch.get("å­èŠ‚ç‚¹", []):
                card = KnowledgeCard(
                    id=f"{book_title}_concept_{branch_name}_{concept}_{timestamp}",
                    book_title=book_title,
                    book_author=book_author,
                    content_type="concept",
                    content=f"{branch_name}: {concept}",
                    tags=[book_title, "æ¦‚å¿µ", branch_name],
                    created_at=timestamp
                )
                self._add_card(card)
                card_ids.append(card.id)

        print(f"âœ… å·²æ·»åŠ  {len(card_ids)} å¼ çŸ¥è¯†å¡ç‰‡åˆ°çŸ¥è¯†åº“")
        return card_ids

    def _add_card(self, card: KnowledgeCard):
        """æ·»åŠ å•å¼ å¡ç‰‡åˆ°å‘é‡æ•°æ®åº“"""
        # ç”Ÿæˆembedding
        text_to_embed = f"{card.content_type}: {card.content}"
        embedding = self.embedder.encode(text_to_embed).tolist()

        # æ·»åŠ åˆ°ChromaDB
        self.collection.add(
            ids=[card.id],
            embeddings=[embedding],
            metadatas=[{
                "book_title": card.book_title,
                "book_author": card.book_author,
                "content_type": card.content_type,
                "tags": json.dumps(card.tags),
                "created_at": card.created_at
            }],
            documents=[card.content]
        )

    def search_knowledge(
        self,
        query: str,
        n_results: int = 5,
        content_type: Optional[str] = None
    ) -> List[Dict]:
        """
        è¯­ä¹‰æœç´¢çŸ¥è¯†åº“
        query: æœç´¢æŸ¥è¯¢ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰
        n_results: è¿”å›ç»“æœæ•°é‡
        content_type: è¿‡æ»¤å†…å®¹ç±»å‹ï¼ˆå¯é€‰ï¼‰
        """
        # ç”ŸæˆæŸ¥è¯¢embedding
        query_embedding = self.embedder.encode(query).tolist()

        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where = {"content_type": content_type} if content_type else None

        # æœç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding],
            n_results=n_results,
            where=where
        )

        # æ ¼å¼åŒ–ç»“æœ
        cards = []
        for i in range(len(results["ids"][0])):
            cards.append({
                "id": results["ids"][0][i],
                "content": results["documents"][0][i],
                "metadata": results["metadatas"][0][i],
                "distance": results["distances"][0][i] if "distances" in results else None
            })

        return cards

    def find_related_books(
        self,
        book_title: str,
        n_results: int = 3
    ) -> List[Dict]:
        """
        æ‰¾åˆ°ä¸æŸæœ¬ä¹¦ç›¸å…³çš„å…¶ä»–ä¹¦ç±
        åŸºäºçŸ¥è¯†å¡çš„è¯­ä¹‰ç›¸ä¼¼åº¦
        """
        # æœç´¢è¿™æœ¬ä¹¦çš„æ‰€æœ‰çŸ¥è¯†å¡
        results = self.search_knowledge(
            query=f"è¿™æœ¬ä¹¦çš„æ ¸å¿ƒè§‚ç‚¹å’Œæ€æƒ³ï¼š{book_title}",
            n_results=20
        )

        # ç»Ÿè®¡å…¶ä»–ä¹¦ç±çš„å‡ºç°é¢‘ç‡
        book_mentions = {}
        for card in results:
            card_book_title = card["metadata"]["book_title"]
            if card_book_title != book_title:
                if card_book_title not in book_mentions:
                    book_mentions[card_book_title] = {
                        "title": card_book_title,
                        "author": card["metadata"]["book_author"],
                        "count": 0,
                        "related_concepts": []
                    }
                book_mentions[card_book_title]["count"] += 1
                book_mentions[card_book_title]["related_concepts"].append(card["content"])

        # æ’åºå¹¶è¿”å›Top N
        sorted_books = sorted(
            book_mentions.values(),
            key=lambda x: x["count"],
            reverse=True
        )

        return sorted_books[:n_results]

    def export_to_markdown(
        self,
        output_path: Optional[str] = None
    ) -> str:
        """
        å¯¼å‡ºçŸ¥è¯†åº“ä¸ºMarkdownæ ¼å¼ï¼ˆå…¼å®¹Obsidianï¼‰
        """
        if output_path is None:
            output_path = self.persist_dir / "knowledge_base.md"

        output_path = Path(output_path)

        # è·å–æ‰€æœ‰çŸ¥è¯†å¡
        all_results = self.collection.get()

        # æŒ‰ä¹¦ç±åˆ†ç»„
        books = {}
        for i, doc_id in enumerate(all_results["ids"]):
            metadata = all_results["metadatas"][i]
            book_title = metadata["book_title"]

            if book_title not in books:
                books[book_title] = {
                    "author": metadata["book_author"],
                    "insights": [],
                    "quotes": [],
                    "concepts": []
                }

            content_type = metadata["content_type"]
            content = all_results["documents"][i]

            if content_type == "insight":
                books[book_title]["insights"].append(content)
            elif content_type == "quote":
                books[book_title]["quotes"].append(content)
            elif content_type == "concept":
                books[book_title]["concepts"].append(content)

        # ç”ŸæˆMarkdown
        markdown = "# æˆ‘çš„çŸ¥è¯†åº“\n\n"
        markdown += f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        markdown += "---\n\n"

        for book_title, book_data in books.items():
            markdown += f## {book_title}\n\n
            markdown += f"**ä½œè€…**: {book_data['author']}\n\n"

            if book_data["insights"]:
                markdown += "### æ ¸å¿ƒè§‚ç‚¹\n\n"
                for insight in book_data["insights"]:
                    markdown += f"- {insight}\n"
                markdown += "\n"

            if book_data["quotes"]:
                markdown += "### é‡‘å¥å¡ç‰‡\n\n"
                for quote in book_data["quotes"]:
                    markdown += f"> {quote}\n\n"
                markdown += "\n"

            if book_data["concepts"]:
                markdown += "### å…³é”®æ¦‚å¿µ\n\n"
                for concept in book_data["concepts"]:
                    markdown += f"- {concept}\n"
                markdown += "\n"

            markdown += "---\n\n"

        # å†™å…¥æ–‡ä»¶
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown)

        print(f"âœ… çŸ¥è¯†åº“å·²å¯¼å‡ºåˆ°: {output_path}")
        return str(output_path)

    def get_knowledge_graph_data(self) -> Dict:
        """
        è·å–çŸ¥è¯†å›¾è°±æ•°æ®ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        è¿”å›å¯ç”¨äºå¯è§†åŒ–åº“ï¼ˆå¦‚pyvisã€networkxï¼‰çš„æ•°æ®
        """
        all_results = self.collection.get()

        nodes = []
        edges = []
        books = set()

        # æ„å»ºèŠ‚ç‚¹
        for i, doc_id in enumerate(all_results["ids"]):
            metadata = all_results["metadatas"][i]
            content = all_results["documents"][i]

            book_title = metadata["book_title"]
            books.add(book_title)

            nodes.append({
                "id": doc_id,
                "label": content[:30] + "..." if len(content) > 30 else content,
                "type": metadata["content_type"],
                "book": book_title
            })

        # æ·»åŠ ä¹¦ç±èŠ‚ç‚¹
        for book in books:
            nodes.append({
                "id": f"book_{book}",
                "label": f"ğŸ“– {book}",
                "type": "book",
                "book": book
            })

        # æ„å»ºè¾¹ï¼ˆçŸ¥è¯†å¡ -> ä¹¦ç±ï¼‰
        for node in nodes:
            if node["type"] != "book":
                edges.append({
                    "from": node["id"],
                    "to": f"book_{node['book']}",
                    "label": "æ¥è‡ª"
                })

        return {
            "nodes": nodes,
            "edges": edges
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆå§‹åŒ–çŸ¥è¯†åº“
    kb = PersonalKnowledgeBase()

    # ç¤ºä¾‹ï¼šæ·»åŠ ä¸€æœ¬ä¹¦çš„çŸ¥è¯†
    book_title = "æ€è€ƒï¼Œå¿«ä¸æ…¢"
    book_author = "ä¸¹å°¼å°”Â·å¡å°¼æ›¼"

    analysis = {
        "key_insights": [
            "äººç±»æ€ç»´æœ‰åŒç³»ç»Ÿï¼šç³»ç»Ÿ1å¿«é€Ÿç›´è§‰ï¼Œç³»ç»Ÿ2ç¼“æ…¢ç†æ€§",
            "æˆ‘ä»¬è¿‡åº¦ä¾èµ–ç›´è§‰ï¼Œå¯¼è‡´å¾ˆå¤šåˆ¤æ–­åå·®"
        ],
        "quotes": [
            "ç›´è§‰æ˜¯å¿«é€Ÿçš„ã€è‡ªåŠ¨çš„ã€æ— æ„è¯†çš„",
            "æ€è€ƒæ˜¯ç¼“æ…¢çš„ã€è´¹åŠ›çš„ã€æœ‰æ„è¯†çš„"
        ],
        "mind_map": {
            "ä¸»è¦åˆ†æ”¯": [
                {
                    "åˆ†æ”¯å": "åŒç³»ç»Ÿç†è®º",
                    "å­èŠ‚ç‚¹": ["ç³»ç»Ÿ1ï¼šå¿«æ€è€ƒ", "ç³»ç»Ÿ2ï¼šæ…¢æ€è€ƒ"]
                },
                {
                    "åˆ†æ”¯å": "è®¤çŸ¥åå·®",
                    "å­èŠ‚ç‚¹": ["é”šå®šæ•ˆåº”", "æŸå¤±åŒæ¶"]
                }
            ]
        }
    }

    kb.add_book_knowledge(book_title, book_author, analysis)

    # æœç´¢çŸ¥è¯†
    print("\n=== æœç´¢ï¼šè®¤çŸ¥åå·® ===")
    results = kb.search_knowledge("è®¤çŸ¥åå·®å¦‚ä½•å½±å“å†³ç­–", n_results=3)
    for result in results:
        print(f"â€¢ {result['content']}")

    # å¯¼å‡ºMarkdown
    kb.export_to_markdown()
